{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0360f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0                                              title  \\\n",
      "0       8476                       You Can Smell Hillary’s Fear   \n",
      "1      10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2       3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3      10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4        875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/ASH-WICUS/data/main/news.csv')\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e064ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8005923000987167\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.array(data[\"title\"])\n",
    "y = np.array(data[\"label\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380eb9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['REAL']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "news_headline = \"Supreme Court considers abortion rights.\"\n",
    "data = cv.transform([news_headline]).toarray()\n",
    "print(model.predict(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636398d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "news_headline = \"Cow dung can cure Corona Virus\"\n",
    "data = cv.transform([news_headline]).toarray()\n",
    "print(model.predict(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e92a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In this exercise, we classified news titles as real or fake, using supervised learning with NLP!\n",
    "# We use pandas alongside scikit-learn to create a sparse text vectorizer to train and \n",
    "# test a simple supervised model. There are many models that we can use to solve this kind of problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "ticker\n",
      "Open\n",
      "Adj Close\n",
      "Epoch 1/10\n",
      "193/193 - 3s - loss: 0.2868\n",
      "Epoch 2/10\n",
      "193/193 - 3s - loss: 0.2671\n",
      "Epoch 3/10\n",
      "193/193 - 3s - loss: 0.2465\n",
      "Epoch 4/10\n",
      "193/193 - 3s - loss: 0.2253\n",
      "Epoch 5/10\n",
      "193/193 - 3s - loss: 0.2040\n",
      "Epoch 6/10\n",
      "193/193 - 3s - loss: 0.1827\n",
      "Epoch 7/10\n",
      "193/193 - 3s - loss: 0.1617\n",
      "Epoch 8/10\n",
      "193/193 - 3s - loss: 0.1413\n",
      "Epoch 9/10\n",
      "193/193 - 3s - loss: 0.1217\n",
      "Epoch 10/10\n",
      "193/193 - 3s - loss: 0.1033\n",
      "1\n",
      "[[67.15351]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A neural network is a network or circuit of neurons, or in a modern sense, an artificial neural network, composed of artificial neurons or nodes.  Thus a neural network is either a biological neural network, made up of real biological neurons, or an artificial neural network, for solving artificial intelligence (AI) problems.\n",
    "\n",
    "# These artificial networks may be used for predictive modeling, adaptive control and applications where they can be trained via a dataset.  Self-learning resulting from experience can occur within networks, which can derive conclusions from a complex and seemingly unrelated set of information.\n",
    "\n",
    "from pandas_datareader import data as wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "start = '2019-06-30'\n",
    "end = '2020-06-30'\n",
    "\n",
    "tickers = ['SBUX']\n",
    "\n",
    "thelen = len(tickers)\n",
    "\n",
    "price_data = []\n",
    "for ticker in tickers:\n",
    "    prices = wb.DataReader(ticker, start = start, end = end, data_source='yahoo')[['Open','Adj Close']]\n",
    "    price_data.append(prices.assign(ticker=ticker)[['ticker', 'Open', 'Adj Close']])\n",
    "\n",
    "#names = np.reshape(price_data, (len(price_data), 1))\n",
    "\n",
    "df = pd.concat(price_data)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "for col in df.columns: \n",
    "    print(col) \n",
    "    \n",
    "#used for setting the output figure size\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "#to normalize the given input data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#to read input data set (place the file name inside  ' ') as shown below\n",
    "df.head()\n",
    "\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "# df.index = names['Date']\n",
    "#3plt.figure(figsize=(16,8))\n",
    "# plt.plot(df['Adj Close'], label='Closing Price')\n",
    "\n",
    "\n",
    "ntrain = 80\n",
    "df_train = df.head(int(len(df)*(ntrain/100)))\n",
    "ntest = -80\n",
    "df_test = df.tail(int(len(df)*(ntest/100)))\n",
    "\n",
    "\n",
    "#importing the packages \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "#dataframe creation\n",
    "seriesdata = df.sort_index(ascending=True, axis=0)\n",
    "new_seriesdata = pd.DataFrame(index=range(0,len(df)),columns=['Date','Adj Close'])\n",
    "length_of_data=len(seriesdata)\n",
    "for i in range(0,length_of_data):\n",
    "    new_seriesdata['Date'][i] = seriesdata['Date'][i]\n",
    "    new_seriesdata['Adj Close'][i] = seriesdata['Adj Close'][i]\n",
    "#setting the index again\n",
    "new_seriesdata.index = new_seriesdata.Date\n",
    "new_seriesdata.drop('Date', axis=1, inplace=True)\n",
    "#creating train and test sets this comprises the entire data’s present in the dataset\n",
    "myseriesdataset = new_seriesdata.values\n",
    "totrain = myseriesdataset[0:255,:]\n",
    "tovalid = myseriesdataset[255:,:]\n",
    "#converting dataset into x_train and y_train\n",
    "scalerdata = MinMaxScaler(feature_range=(0, 1))\n",
    "scale_data = scalerdata.fit_transform(myseriesdataset)\n",
    "x_totrain, y_totrain = [], []\n",
    "length_of_totrain=len(totrain)\n",
    "for i in range(60,length_of_totrain):\n",
    "    x_totrain.append(scale_data[i-60:i,0])\n",
    "    y_totrain.append(scale_data[i,0])\n",
    "x_totrain, y_totrain = np.array(x_totrain), np.array(y_totrain)\n",
    "x_totrain = np.reshape(x_totrain, (x_totrain.shape[0],x_totrain.shape[1],1))\n",
    "\n",
    "\n",
    "#LSTM neural network\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(x_totrain.shape[1],1)))\n",
    "lstm_model.add(LSTM(units=50))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "lstm_model.fit(x_totrain, y_totrain, epochs=10, batch_size=1, verbose=2)\n",
    "#predicting next data stock price\n",
    "myinputs = new_seriesdata[len(new_seriesdata) - (len(tovalid)+1) - 60:].values\n",
    "myinputs = myinputs.reshape(-1,1)\n",
    "myinputs  = scalerdata.transform(myinputs)\n",
    "tostore_test_result = []\n",
    "for i in range(60,myinputs.shape[0]):\n",
    "    tostore_test_result.append(myinputs[i-60:i,0])\n",
    "tostore_test_result = np.array(tostore_test_result)\n",
    "tostore_test_result = np.reshape(tostore_test_result,(tostore_test_result.shape[0],tostore_test_result.shape[1],1))\n",
    "myclosing_priceresult = lstm_model.predict(tostore_test_result)\n",
    "myclosing_priceresult = scalerdata.inverse_transform(myclosing_priceresult)\n",
    "\n",
    "    \n",
    "totrain = df_train\n",
    "tovalid = df_test\n",
    "\n",
    "#predicting next data stock price\n",
    "myinputs = new_seriesdata[len(new_seriesdata) - (len(tovalid)+1) - 60:].values\n",
    "\n",
    "#  Printing the next day’s predicted stock price. \n",
    "print(len(tostore_test_result));\n",
    "print(myclosing_priceresult);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In this experiment we took one calendar year of data, fed it into the RNN model, and asked it to predict the next day's closing price.  The time series started on 6/30/2019 and ended on 6/30/2020, so we are trying to predict the closing price for 07/01/2020.  The model said it would be 67.15.  On 07/01/2020, SBUX actually closed at 74.03.  The stock closed around 10% hgher than the model predicted.  Although this sounds great, and we would have hypothetically made an extra 10% on our investment, we would have preferred to see the model make a better prediction, which perhaps, would be off by 1% or 2%, but not 10%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data:\n",
    "# All data is imported from Yahoo Finance.  Yahoo sources the data from Capital IQ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

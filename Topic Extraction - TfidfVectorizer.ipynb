{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "#import pdftotext\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "securities    total         loans         credit        billion       \n",
      "value         capital       assets        risk          september     \n",
      "million       balance       financial     net           income        \n",
      "fair          common        commercial    losses        mortgage      \n",
      "debt          stock         real          loan          securities    \n",
      "equity        equity        estate        management    quarter       \n",
      "rate          average       derivatives   gains         months        \n",
      "contracts     table         mortgage      millions      december      \n",
      "total         consumer      liabilities   company       changes       \n",
      "term          sep           pci           allowance     ended         \n",
      "\n",
      "\n",
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Jul/2020 10:00:57] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jul/2020 10:00:57] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jul/2020 10:00:57] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jul/2020 10:00:57] code 404, message Not Found\n",
      "127.0.0.1 - - [19/Jul/2020 10:00:57] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jul/2020 10:00:57] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('C:\\\\Users\\\\ryans\\\\OneDrive\\\\Desktop\\\\Briefcase\\\\PDFs\\\\1-ALL PYTHON & R CODE SAMPLES\\\\Topic Extraction\\\\Finance10K.txt') as f:\n",
    "    clean_cont = f.read().splitlines()\n",
    "\n",
    "\n",
    "clean_cont\n",
    "\n",
    "\n",
    "doc=[i.replace('\\xe2\\x80\\x9c','') for i in clean_cont ]\n",
    "doc=[i.replace('\\xe2\\x80\\x9d','') for i in doc ]\n",
    "doc=[i.replace('\\xe2\\x80\\x99s','') for i in doc ]\n",
    "\n",
    "docs = [x for x in doc if x != ' ']\n",
    "docss = [x for x in docs if x != '']\n",
    "\n",
    "\n",
    "doc\n",
    "\n",
    "docs\n",
    "\n",
    "docss\n",
    "\n",
    "\n",
    "financedoc=[re.sub(\"[^a-zA-Z]+\", \" \", s) for s in docss]\n",
    "financedoc\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#%pylab\n",
    "#%matplotlib inline\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "vect=CountVectorizer(ngram_range=(1,1),stop_words='english')\n",
    "\n",
    "\n",
    "fin=vect.fit_transform(financedoc)\n",
    "\n",
    "\n",
    "fin\n",
    "\n",
    "\n",
    "pd.DataFrame(fin.toarray(),columns=vect.get_feature_names())\n",
    "\n",
    "\n",
    "\n",
    "lda=LatentDirichletAllocation(n_components=5)\n",
    "\n",
    "\n",
    "lda.fit_transform(fin)\n",
    "\n",
    "\n",
    "lda_dtf=lda.fit_transform(fin)\n",
    "\n",
    "\n",
    "sorting=np.argsort(lda.components_)[:,::-1]\n",
    "features=np.array(vect.get_feature_names())\n",
    "\n",
    "\n",
    "import mglearn\n",
    "mglearn.tools.print_topics(topics=range(5), feature_names=features,\n",
    "sorting=sorting, topics_per_chunk=5, n_words=10)\n",
    "\n",
    "\n",
    "\n",
    "#from __future__ import  print_function\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "\n",
    "zit=pyLDAvis.sklearn.prepare(lda,fin,vect)\n",
    "\n",
    "\n",
    "\n",
    "pyLDAvis.show(zit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate Word Cloud\n",
    "# type(clean_cont)\n",
    "# convert list to string\n",
    "str = ''.join(clean_cont)\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(str) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data:\n",
    "# https://github.com/aniruddhachoudhury/NLP-Topic-Extraction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
